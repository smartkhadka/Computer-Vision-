{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":28903,"sourceType":"datasetVersion","datasetId":22535},{"sourceId":13827746,"sourceType":"datasetVersion","datasetId":8806369}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os                       # for working with files\nimport numpy as np              # for numerical computationss\nimport pandas as pd             # for working with dataframes\nimport torch                    # Pytorch module \nimport matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\nimport torch.nn as nn           # for creating  neural networks\nfrom torch.utils.data import DataLoader # for dataloaders \nfrom PIL import Image           # for checking images\nimport torch.nn.functional as F # for functions for calculating loss\nimport torchvision.transforms as transforms   # for transforming images into tensors \nfrom torchvision.utils import make_grid       # for data checking\nfrom torchvision.datasets import ImageFolder  # for working with classes and images\nfrom torchsummary import summary  \nfrom torchvision import models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:17:17.599693Z","iopub.execute_input":"2025-11-22T15:17:17.600271Z","iopub.status.idle":"2025-11-22T15:17:17.604796Z","shell.execute_reply.started":"2025-11-22T15:17:17.600248Z","shell.execute_reply":"2025-11-22T15:17:17.603995Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"data_dir = \"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\ntrain_dir = data_dir + \"/train\"\nvalid_dir = data_dir + \"/valid\"\ndiseases = os.listdir(train_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:16:28.189658Z","iopub.execute_input":"2025-11-22T15:16:28.190249Z","iopub.status.idle":"2025-11-22T15:16:28.207201Z","shell.execute_reply.started":"2025-11-22T15:16:28.190222Z","shell.execute_reply":"2025-11-22T15:16:28.206590Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# printing the disease names\nprint(diseases)\nprint(\"Total disease classes are: {}\".format(len(diseases)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:16:36.642738Z","iopub.execute_input":"2025-11-22T15:16:36.643315Z","iopub.status.idle":"2025-11-22T15:16:36.647462Z","shell.execute_reply.started":"2025-11-22T15:16:36.643290Z","shell.execute_reply":"2025-11-22T15:16:36.646703Z"}},"outputs":[{"name":"stdout","text":"['Tomato___Late_blight', 'Tomato___healthy', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Potato___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Tomato___Early_blight', 'Tomato___Septoria_leaf_spot', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Strawberry___Leaf_scorch', 'Peach___healthy', 'Apple___Apple_scab', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Bacterial_spot', 'Apple___Black_rot', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Peach___Bacterial_spot', 'Apple___Cedar_apple_rust', 'Tomato___Target_Spot', 'Pepper,_bell___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Potato___Late_blight', 'Tomato___Tomato_mosaic_virus', 'Strawberry___healthy', 'Apple___healthy', 'Grape___Black_rot', 'Potato___Early_blight', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Common_rust_', 'Grape___Esca_(Black_Measles)', 'Raspberry___healthy', 'Tomato___Leaf_Mold', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Pepper,_bell___Bacterial_spot', 'Corn_(maize)___healthy']\nTotal disease classes are: 38\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\nplants = []\nNumberOfDiseases = 0\nfor plant in diseases:\n    if plant.split('___')[0] not in plants:\n        plants.append(plant.split('___')[0])\n    if plant.split('___')[1] != 'healthy':\n        NumberOfDiseases += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:16:37.603256Z","iopub.execute_input":"2025-11-22T15:16:37.604161Z","iopub.status.idle":"2025-11-22T15:16:37.608443Z","shell.execute_reply.started":"2025-11-22T15:16:37.604127Z","shell.execute_reply":"2025-11-22T15:16:37.607692Z"}},"outputs":[],"execution_count":8},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"# number of unique diseases\nprint(\"Number of diseases: {}\".format(NumberOfDiseases))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:16:40.173085Z","iopub.execute_input":"2025-11-22T15:16:40.173599Z","iopub.status.idle":"2025-11-22T15:16:40.177447Z","shell.execute_reply.started":"2025-11-22T15:16:40.173576Z","shell.execute_reply":"2025-11-22T15:16:40.176847Z"}},"outputs":[{"name":"stdout","text":"Number of diseases: 26\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Number of images for each disease\nnums = {}\nfor disease in diseases:\n    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n    \n# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n\nimg_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\nimg_per_class","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:16:40.824713Z","iopub.execute_input":"2025-11-22T15:16:40.825407Z","iopub.status.idle":"2025-11-22T15:16:45.752227Z","shell.execute_reply.started":"2025-11-22T15:16:40.825384Z","shell.execute_reply":"2025-11-22T15:16:45.751417Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                    no. of images\nTomato___Late_blight                                         1851\nTomato___healthy                                             1926\nGrape___healthy                                              1692\nOrange___Haunglongbing_(Citrus_greening)                     2010\nSoybean___healthy                                            2022\nSquash___Powdery_mildew                                      1736\nPotato___healthy                                             1824\nCorn_(maize)___Northern_Leaf_Blight                          1908\nTomato___Early_blight                                        1920\nTomato___Septoria_leaf_spot                                  1745\nCorn_(maize)___Cercospora_leaf_spot Gray_leaf_spot           1642\nStrawberry___Leaf_scorch                                     1774\nPeach___healthy                                              1728\nApple___Apple_scab                                           2016\nTomato___Tomato_Yellow_Leaf_Curl_Virus                       1961\nTomato___Bacterial_spot                                      1702\nApple___Black_rot                                            1987\nBlueberry___healthy                                          1816\nCherry_(including_sour)___Powdery_mildew                     1683\nPeach___Bacterial_spot                                       1838\nApple___Cedar_apple_rust                                     1760\nTomato___Target_Spot                                         1827\nPepper,_bell___healthy                                       1988\nGrape___Leaf_blight_(Isariopsis_Leaf_Spot)                   1722\nPotato___Late_blight                                         1939\nTomato___Tomato_mosaic_virus                                 1790\nStrawberry___healthy                                         1824\nApple___healthy                                              2008\nGrape___Black_rot                                            1888\nPotato___Early_blight                                        1939\nCherry_(including_sour)___healthy                            1826\nCorn_(maize)___Common_rust_                                  1907\nGrape___Esca_(Black_Measles)                                 1920\nRaspberry___healthy                                          1781\nTomato___Leaf_Mold                                           1882\nTomato___Spider_mites Two-spotted_spider_mite                1741\nPepper,_bell___Bacterial_spot                                1913\nCorn_(maize)___healthy                                       1859","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>no. of images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tomato___Late_blight</th>\n      <td>1851</td>\n    </tr>\n    <tr>\n      <th>Tomato___healthy</th>\n      <td>1926</td>\n    </tr>\n    <tr>\n      <th>Grape___healthy</th>\n      <td>1692</td>\n    </tr>\n    <tr>\n      <th>Orange___Haunglongbing_(Citrus_greening)</th>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>Soybean___healthy</th>\n      <td>2022</td>\n    </tr>\n    <tr>\n      <th>Squash___Powdery_mildew</th>\n      <td>1736</td>\n    </tr>\n    <tr>\n      <th>Potato___healthy</th>\n      <td>1824</td>\n    </tr>\n    <tr>\n      <th>Corn_(maize)___Northern_Leaf_Blight</th>\n      <td>1908</td>\n    </tr>\n    <tr>\n      <th>Tomato___Early_blight</th>\n      <td>1920</td>\n    </tr>\n    <tr>\n      <th>Tomato___Septoria_leaf_spot</th>\n      <td>1745</td>\n    </tr>\n    <tr>\n      <th>Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot</th>\n      <td>1642</td>\n    </tr>\n    <tr>\n      <th>Strawberry___Leaf_scorch</th>\n      <td>1774</td>\n    </tr>\n    <tr>\n      <th>Peach___healthy</th>\n      <td>1728</td>\n    </tr>\n    <tr>\n      <th>Apple___Apple_scab</th>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>Tomato___Tomato_Yellow_Leaf_Curl_Virus</th>\n      <td>1961</td>\n    </tr>\n    <tr>\n      <th>Tomato___Bacterial_spot</th>\n      <td>1702</td>\n    </tr>\n    <tr>\n      <th>Apple___Black_rot</th>\n      <td>1987</td>\n    </tr>\n    <tr>\n      <th>Blueberry___healthy</th>\n      <td>1816</td>\n    </tr>\n    <tr>\n      <th>Cherry_(including_sour)___Powdery_mildew</th>\n      <td>1683</td>\n    </tr>\n    <tr>\n      <th>Peach___Bacterial_spot</th>\n      <td>1838</td>\n    </tr>\n    <tr>\n      <th>Apple___Cedar_apple_rust</th>\n      <td>1760</td>\n    </tr>\n    <tr>\n      <th>Tomato___Target_Spot</th>\n      <td>1827</td>\n    </tr>\n    <tr>\n      <th>Pepper,_bell___healthy</th>\n      <td>1988</td>\n    </tr>\n    <tr>\n      <th>Grape___Leaf_blight_(Isariopsis_Leaf_Spot)</th>\n      <td>1722</td>\n    </tr>\n    <tr>\n      <th>Potato___Late_blight</th>\n      <td>1939</td>\n    </tr>\n    <tr>\n      <th>Tomato___Tomato_mosaic_virus</th>\n      <td>1790</td>\n    </tr>\n    <tr>\n      <th>Strawberry___healthy</th>\n      <td>1824</td>\n    </tr>\n    <tr>\n      <th>Apple___healthy</th>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>Grape___Black_rot</th>\n      <td>1888</td>\n    </tr>\n    <tr>\n      <th>Potato___Early_blight</th>\n      <td>1939</td>\n    </tr>\n    <tr>\n      <th>Cherry_(including_sour)___healthy</th>\n      <td>1826</td>\n    </tr>\n    <tr>\n      <th>Corn_(maize)___Common_rust_</th>\n      <td>1907</td>\n    </tr>\n    <tr>\n      <th>Grape___Esca_(Black_Measles)</th>\n      <td>1920</td>\n    </tr>\n    <tr>\n      <th>Raspberry___healthy</th>\n      <td>1781</td>\n    </tr>\n    <tr>\n      <th>Tomato___Leaf_Mold</th>\n      <td>1882</td>\n    </tr>\n    <tr>\n      <th>Tomato___Spider_mites Two-spotted_spider_mite</th>\n      <td>1741</td>\n    </tr>\n    <tr>\n      <th>Pepper,_bell___Bacterial_spot</th>\n      <td>1913</td>\n    </tr>\n    <tr>\n      <th>Corn_(maize)___healthy</th>\n      <td>1859</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# datasets for validation and training\ntrain = ImageFolder(train_dir, transform=transforms.ToTensor())\nvalid = ImageFolder(valid_dir, transform=transforms.ToTensor()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:18:37.678394Z","iopub.execute_input":"2025-11-22T15:18:37.679171Z","iopub.status.idle":"2025-11-22T15:20:14.259602Z","shell.execute_reply.started":"2025-11-22T15:18:37.679146Z","shell.execute_reply":"2025-11-22T15:20:14.258824Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrainloader = DataLoader(train, batch_size=32, shuffle=True, num_workers=2)\ntestloader = DataLoader(valid, batch_size=32, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:20:17.968016Z","iopub.execute_input":"2025-11-22T15:20:17.968549Z","iopub.status.idle":"2025-11-22T15:20:17.972871Z","shell.execute_reply.started":"2025-11-22T15:20:17.968522Z","shell.execute_reply":"2025-11-22T15:20:17.972103Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import torch\n\n# Check if CUDA is available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")  # Use GPU\n    print(\"Using GPU:\", torch.cuda.get_device_name(0))\nelse:\n    device = torch.device(\"cpu\")   # Fallback to CPU\n    print(\"CUDA not available, using CPU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:21:14.703397Z","iopub.execute_input":"2025-11-22T15:21:14.704238Z","iopub.status.idle":"2025-11-22T15:21:14.791809Z","shell.execute_reply.started":"2025-11-22T15:21:14.704212Z","shell.execute_reply":"2025-11-22T15:21:14.791077Z"}},"outputs":[{"name":"stdout","text":"Using GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# total number of classes in train set\nlen(train.classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:21:54.910962Z","iopub.execute_input":"2025-11-22T15:21:54.911426Z","iopub.status.idle":"2025-11-22T15:21:54.916261Z","shell.execute_reply.started":"2025-11-22T15:21:54.911403Z","shell.execute_reply":"2025-11-22T15:21:54.915680Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"38"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"model =  models.resnet18(pretrained=True).to(device)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:21:58.800486Z","iopub.execute_input":"2025-11-22T15:21:58.801077Z","iopub.status.idle":"2025-11-22T15:21:59.168766Z","shell.execute_reply.started":"2025-11-22T15:21:58.801056Z","shell.execute_reply":"2025-11-22T15:21:59.167973Z"}},"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import torch.nn.functional as F\nclass Dc_Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1=nn.Linear(512,120)\n        self.linear2=nn.Linear(120,38)\n\n    def forward(self,x):\n        x=F.relu(self.linear1(x))\n        x=self.linear2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:22:19.689723Z","iopub.execute_input":"2025-11-22T15:22:19.690400Z","iopub.status.idle":"2025-11-22T15:22:19.694802Z","shell.execute_reply.started":"2025-11-22T15:22:19.690376Z","shell.execute_reply":"2025-11-22T15:22:19.694011Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model_=Dc_Model().to(device)\nmodel_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:22:22.746271Z","iopub.execute_input":"2025-11-22T15:22:22.746795Z","iopub.status.idle":"2025-11-22T15:22:22.752930Z","shell.execute_reply.started":"2025-11-22T15:22:22.746761Z","shell.execute_reply":"2025-11-22T15:22:22.752324Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Dc_Model(\n  (linear1): Linear(in_features=512, out_features=120, bias=True)\n  (linear2): Linear(in_features=120, out_features=38, bias=True)\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"model.fc = model_\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:22:26.344802Z","iopub.execute_input":"2025-11-22T15:22:26.345374Z","iopub.status.idle":"2025-11-22T15:22:26.350225Z","shell.execute_reply.started":"2025-11-22T15:22:26.345351Z","shell.execute_reply":"2025-11-22T15:22:26.349469Z"}},"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Dc_Model(\n    (linear1): Linear(in_features=512, out_features=120, bias=True)\n    (linear2): Linear(in_features=120, out_features=38, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"for param in model.parameters():\n        param.requires_grad = False\nfor param in model.fc.parameters():\n        param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:22:30.794214Z","iopub.execute_input":"2025-11-22T15:22:30.794798Z","iopub.status.idle":"2025-11-22T15:22:30.798730Z","shell.execute_reply.started":"2025-11-22T15:22:30.794774Z","shell.execute_reply":"2025-11-22T15:22:30.798038Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import torch.optim as optim\ncriterion=nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:22:51.858324Z","iopub.execute_input":"2025-11-22T15:22:51.859198Z","iopub.status.idle":"2025-11-22T15:22:51.863381Z","shell.execute_reply.started":"2025-11-22T15:22:51.859167Z","shell.execute_reply":"2025-11-22T15:22:51.862585Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"train_loss = []\nval_loss = []\n\nepochs = 2\n\nfor epoch in range(epochs):\n      print(\"epoch {}/{}\".format(epoch+1,epochs))\n      running_loss = 0.0\n      running_score = 0.0\n#       model.train()\n      for image,label in trainloader:\n          image = image.to(device)\n          label = label.to(device)\n          optimizer.zero_grad()\n          y_pred = model(image)\n          loss = criterion(y_pred,label)         \n          loss.backward() #calculate derivatives \n          optimizer.step() # update parameters\n          val, index_ = torch.max(y_pred,axis=1)\n          running_score += torch.sum(index_ == label.data).item()\n          running_loss += loss.item()\n      \n      epoch_score = running_score/len(trainloader.dataset)\n      epoch_loss = running_loss/len(trainloader.dataset)\n      train_loss.append(epoch_loss)\n      print(\"Training loss: {}, accuracy: {}\".format(epoch_loss,epoch_score))\n      \n      with torch.no_grad():\n          model.eval()\n          running_loss = 0.0\n          running_score = 0.0\n          for image,label in testloader:\n                image = image.to(device)\n                label = label.to(device)\n                optimizer.zero_grad()\n                y_pred = model(image)\n                loss = criterion(y_pred,label)\n                running_loss += loss.item()\n\n                val, index_ = torch.max(y_pred,axis=1)\n                running_score += torch.sum(index_ == label.data).item()\n          \n          epoch_score = running_score/len(testloader.dataset)\n          epoch_loss = running_loss/len(testloader.dataset)\n          val_loss.append(epoch_loss)\n          print(\"Validation loss: {}, accuracy: {}\".format(epoch_loss,epoch_score))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:22:54.213829Z","iopub.execute_input":"2025-11-22T15:22:54.214406Z","iopub.status.idle":"2025-11-22T15:31:28.835279Z","shell.execute_reply.started":"2025-11-22T15:22:54.214386Z","shell.execute_reply":"2025-11-22T15:31:28.834281Z"}},"outputs":[{"name":"stdout","text":"epoch 1/2\nTraining loss: 0.015562134678659386, accuracy: 0.8689807240913294\nValidation loss: 0.006659749147807029, accuracy: 0.9293762804461644\nepoch 2/2\nTraining loss: 0.004711830348928526, accuracy: 0.9506366028878298\nValidation loss: 0.0046514177685290535, accuracy: 0.9508308672888687\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"test_dir = \"/kaggle/input/potato/Screenshot 2025-11-22 213058.jpg\"\ntest = ImageFolder(test_dir, transform=transforms.ToTensor())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_image(img, model):\n    \"\"\"Converts image to array and return the predicted class\n        with highest probability\"\"\"\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n\n    return train.classes[preds[0].item()]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# predicting first image\nimg, label = test[0]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_images[0], ', Predicted:', predict_image(img, model))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}